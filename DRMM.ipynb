{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T01:57:29.378263Z",
     "start_time": "2020-08-03T01:57:07.327898Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from ast import literal_eval\n",
    "from utility.utility import ndcg, mAP_score, highlight, history_plot, generate_pairwise_dataset\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:12.607Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, input_dims=5, **kwargs):\n",
    "        super(Dense, self).__init__(name='Linear', **kwargs)\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.units = units\n",
    "        self.input_dims = input_dims\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer = tf.keras.initializers.he_normal()\n",
    "        self.w = self.add_weight(\n",
    "            shape=(self.input_dims, self.units),\n",
    "            initializer=initializer,\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), \n",
    "            initializer=tf.zeros_initializer, \n",
    "            trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.ragged.map_flat_values(tf.matmul, inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:12.834Z"
    }
   },
   "outputs": [],
   "source": [
    "class Word_Matching_Network(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Word_Matching_Network, self).__init__(name='Word_Matching_Network')\n",
    "        self._supports_ragged_inputs = True        \n",
    "        self.Layer1 = Dense(5, input_dims=30)\n",
    "        self.Layer2 = Dense(5, input_dims=5)\n",
    "        self.Layer3 = Dense(1, input_dims=5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.Layer1(inputs)\n",
    "        x = tf.ragged.map_flat_values(tf.nn.relu, x)\n",
    "        \n",
    "        x = self.Layer2(x)\n",
    "        x = tf.ragged.map_flat_values(tf.nn.relu, x)\n",
    "        \n",
    "        x = self.Layer3(x)\n",
    "        x = tf.ragged.map_flat_values(tf.nn.relu, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.067Z"
    }
   },
   "outputs": [],
   "source": [
    "class Gating_Network(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Gating_Network, self).__init__()\n",
    "        self._supports_ragged_inputs = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "        self.w = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            name='Gating_weight',\n",
    "            initializer=initializer,\n",
    "            trainable=True)\n",
    "\n",
    "    def call(self, idf):\n",
    "        g = tf.math.multiply(idf, self.w)\n",
    "        softmax = tf.ragged.map_flat_values(tf.nn.softmax, g)\n",
    "        return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.267Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score_Aggregation(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Score_Aggregation, self).__init__(name='Score_Aggregation')\n",
    "        self._supports_ragged_inputs = True\n",
    "        BN = keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, Z, g):\n",
    "        score = tf.ragged.map_flat_values(tf.reshape, Z, shape=(-1, ))\n",
    "        gating = g\n",
    "        s_g_sum = tf.math.multiply(gating, score)\n",
    "        rel = tf.math.reduce_sum(s_g_sum, axis=1)\n",
    "        return tf.keras.activations.sigmoid(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.492Z"
    }
   },
   "outputs": [],
   "source": [
    "class DRMM(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DRMM, self).__init__(name='DRMM')\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.Word_Matching_Network = Word_Matching_Network()\n",
    "        self.Gating_Network = Gating_Network()\n",
    "        self.Score_Aggregation = Score_Aggregation()\n",
    "\n",
    "    def call(self, inputs, idf):\n",
    "        Z = self.Word_Matching_Network(inputs)\n",
    "        G = self.Gating_Network(idf)\n",
    "        score = self.Score_Aggregation(Z, G)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pairwise_DRMM(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Pairwise_DRMM, self).__init__(name='Pairwise_DRMM')\n",
    "        self.drmm = DRMM()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        positive_hist = inputs['positive_hist']\n",
    "        negative_hist = inputs['negative_hist']\n",
    "        query_idf = inputs['query_idf']\n",
    "        \n",
    "        positive = self.drmm(positive_hist, query_idf)\n",
    "        negative = self.drmm(negative_hist, query_idf)\n",
    "        \n",
    "        return tf.concat([positive, negative], axis=0) \n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        hist = inputs['hist']\n",
    "        query_idf = inputs['query_idf']\n",
    "        score = self.drmm(hist, query_idf)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.707Z"
    }
   },
   "outputs": [],
   "source": [
    "def Pairwise_ranking_loss(y_true, y_pred):\n",
    "    '''\n",
    "    ignore y_true\n",
    "    '''\n",
    "    positive_score = tf.keras.layers.Lambda(lambda x: x[:len(x)//2], output_shape= (1,))(y_pred)\n",
    "    negative_score = tf.keras.layers.Lambda(lambda x: x[len(x)//2:], output_shape= (1,))(y_pred)\n",
    "\n",
    "    return tf.keras.backend.mean(tf.math.maximum(0., 1 - positive_score + negative_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "df = pd.read_csv('./data/paccr_drmm_.csv', converters={\"positive_hist\": literal_eval, \n",
    "                                                       \"negative_hist\": literal_eval,\n",
    "                                                       \"query_idf\": literal_eval})\n",
    "\n",
    "df = df[['query_len', 'query_preprocessed', 'positive_hist', 'negative_hist', 'query_idf']]\n",
    "\n",
    "test = pd.read_csv('./data/paccr_drmm_test.csv', converters={\"hist\": literal_eval,\n",
    "                                                             \"query_idf\": literal_eval})\n",
    "\n",
    "dev_q = set(random.sample(list(df['query_preprocessed'].unique()), 40))\n",
    "train_q = set(df['query_preprocessed'].unique()) - dev_q\n",
    "\n",
    "train = pd.concat([df.groupby('query_preprocessed').get_group(name) for name in train_q]).sample(frac=1).reset_index(drop=True)\n",
    "dev = pd.concat([df.groupby('query_preprocessed').get_group(name) for name in dev_q]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "metadata = {'query_idf': tf.ragged.constant(train.query_idf, dtype=tf.float32, ragged_rank=1),\n",
    "            'positive_hist': tf.ragged.constant(train.positive_hist, dtype=tf.float32, ragged_rank=1),\n",
    "            'negative_hist': tf.ragged.constant(train.negative_hist, dtype=tf.float32, ragged_rank=1)}\n",
    "\n",
    "metadata_dev = {'query_idf': tf.ragged.constant(dev.query_idf, dtype=tf.float32, ragged_rank=1),\n",
    "                'positive_hist': tf.ragged.constant(dev.positive_hist, dtype=tf.float32, ragged_rank=1),\n",
    "                'negative_hist': tf.ragged.constant(dev.negative_hist, dtype=tf.float32, ragged_rank=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(metadata)\n",
    "ds = ds.shuffle(buffer_size=len(train))\n",
    "batchs = 128\n",
    "ds = ds.batch(batchs).repeat()\n",
    "example_batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:25.640Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Pairwise_DRMM()\n",
    "learning_rate = .1\n",
    "print_step = 1\n",
    "n=20\n",
    "optimizer = tf.keras.optimizers.Adagrad (learning_rate=learning_rate)\n",
    "print(Pairwise_ranking_loss(y_true=None, y_pred=model(example_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sum = 0\n",
    "ndcg_sum = 0\n",
    "step_history = []\n",
    "loss_history = []\n",
    "loss_history_dev = []\n",
    "ndcg_history = []\n",
    "\n",
    "start = time.time()\n",
    "for step, batch_train in enumerate(ds):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(batch_train)\n",
    "        loss_value = Pairwise_ranking_loss(y_true=None, y_pred=logits)\n",
    "        loss_sum += loss_value \n",
    "        \n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    if step % print_step == 0:\n",
    "        current_loss_average = float(loss_sum)/print_step\n",
    "        if step ==0:\n",
    "            current_loss_average = loss_sum\n",
    "        current_ndcg_average = float(ndcg_sum)/print_step\n",
    "        \n",
    "        logits_dev = model(metadata_dev)\n",
    "        current_loss_average_dev = Pairwise_ranking_loss(y_true=None, y_pred=logits_dev)\n",
    "        loss_sum = 0\n",
    "        \n",
    "        for q in dev_q:\n",
    "            ndcg_test = test[test['query_preprocessed'] == q]\n",
    "            metadata_ndcg = {'query_idf': tf.ragged.constant(ndcg_test['query_idf'], dtype=tf.float32, ragged_rank=1),\n",
    "                             'hist': tf.ragged.constant(ndcg_test['hist'], dtype=tf.float32, ragged_rank=1)}\n",
    "                \n",
    "            ndcg_test['rel'] = model.predict(metadata_ndcg).numpy()\n",
    "            rel_pred = list(ndcg_test.sort_values(by=['rel'], axis=0, ascending=False)['median_relevance']-1)\n",
    "            ndcg_sum += ndcg(rel_pred, p=n, form=\"exp\")\n",
    "            \n",
    "        current_ndcg_average = ndcg_sum/len(dev_q)\n",
    "        step_history.append(step)\n",
    "        loss_history.append(current_loss_average)\n",
    "        loss_history_dev.append(current_loss_average_dev)\n",
    "        ndcg_history.append(current_ndcg_average)\n",
    "        \n",
    "        print(\"Training loss at step %d: %.5f, dev_loss : %.5f, nDCG@20 : %.5f\"% (step, \n",
    "                                                                  current_loss_average, \n",
    "                                                                  current_loss_average_dev,\n",
    "                                                                  current_ndcg_average))\n",
    "        \n",
    "        print(\"Seen so far: %s train samples, learning rate: %.4f\" % ((step + 1) * batchs, learning_rate))\n",
    "        ndcg_sum = 0\n",
    "        start = time.time()\n",
    "        \n",
    "    if step == 200:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 392,
   "position": {
    "height": "414px",
    "left": "766px",
    "right": "20px",
    "top": "27px",
    "width": "518px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
