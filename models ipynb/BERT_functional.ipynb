{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T10:22:37.272321Z",
     "start_time": "2020-08-01T10:22:30.116422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "import sentencepiece as spm\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.raw_ops import RaggedTensorToVariant\n",
    "\n",
    "@tf.RegisterGradient(\"RaggedTensorFromVariant\")\n",
    "def _RaggedTensorFromVariantGrad(*args):\n",
    "    if len(args) == 2:\n",
    "        op, grad = args\n",
    "        res = [RaggedTensorToVariant(rt_nested_splits=[], rt_dense_values=grad,\n",
    "                                      batched_input=False)]\n",
    "    else:\n",
    "        op, empty, grad = args\n",
    "        res = [RaggedTensorToVariant(rt_nested_splits=[op.outputs[0]], rt_dense_values=grad,\n",
    "                                    batched_input=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T08:42:31.378846Z",
     "start_time": "2020-08-01T08:42:31.137986Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv').fillna('')\n",
    "# test = pd.read_csv('./data/test.csv').fillna('')\n",
    "# test_df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['query'] = train.apply(lambda x: x['query'].lower(), axis=1)\n",
    "train['product_title'] = train.apply(lambda x: x['product_title'].lower(), axis=1)\n",
    "train['product_description'] = train.apply(lambda x: x['product_description'].lower(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = list(train['query'].unique()) + \\\n",
    "                  list(train['product_title'].unique()) + \\\n",
    "                  list(train['product_description'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sentences_.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(sentences_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = '--input={} --model_prefix={} --vocab_size={} --user_defined_symbols={} --model_type={}'\n",
    "\n",
    "input_file = './sentences_.txt'\n",
    "model_prefix = 'sentences_'\n",
    "vocab_size = 5000\n",
    "user_defined_symbols = '▁[PAD],▁[UNK],▁[CLS],▁[SEP],▁[MASK]'\n",
    "model_type = 'bpe'\n",
    "\n",
    "cmd = parameter.format(input_file, model_prefix, vocab_size, user_defined_symbols, model_type)\n",
    "spm.SentencePieceTrainer.Train(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = pd.read_csv('./sentences_.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_size = len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = './sentences_.model'\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['query_processed'] = train.apply(lambda x: sp.encode_as_ids(x['query']), axis=1)\n",
    "train['product_title_processed'] = train.apply(lambda x: sp.encode_as_ids(x['product_title']), axis=1)\n",
    "train['product_description_processed'] = train.apply(lambda x: sp.encode_as_ids(x['product_description']), axis=1)\n",
    "train['NSP_label'] = train.apply(lambda x: 0 if random.uniform(0, 1) <0.5 else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dict = {}\n",
    "for q in train['query'].unique():\n",
    "    q_dict[q] = train.groupby('query').get_group(q)['product_title_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(train['query'].unique())\n",
    "def sentence_change(x):\n",
    "    if x['NSP_label'] == 0:\n",
    "        tmp = random.choice(temp)\n",
    "        while tmp == x['query']:\n",
    "            tmp = random.choice(temp)\n",
    "        return random.choice(list(q_dict[tmp]))\n",
    "    return x['product_title_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['changed_product_title'] = train.apply(lambda x: sentence_change(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del q_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mask(x):\n",
    "    new_query = []\n",
    "    masked_indexes = []\n",
    "    for i, w in enumerate(x):\n",
    "        if random.uniform(0, 1) <= 0.15:\n",
    "            if random.uniform(0, 1) <= 0.8:\n",
    "                new_query.append(7)\n",
    "                masked_indexes.append(i)\n",
    "            elif random.uniform(0, 1) <= 0.5:\n",
    "                random_word = random.randint(8, vocab_size-8)\n",
    "                new_query.append(random_word)\n",
    "                masked_indexes.append(i)\n",
    "            else :\n",
    "                new_query.append(w)\n",
    "                masked_indexes.append(i)\n",
    "        else :\n",
    "            new_query.append(w)\n",
    "    return new_query, masked_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(x):\n",
    "    query, label = _mask(x['query_processed'])\n",
    "    x['masked_query'] = [5] + query + [6]\n",
    "    query_label = [l+1 for l in label]\n",
    "    title, label = _mask(x['changed_product_title'])\n",
    "    x['masked_product_title'] = title + [6]\n",
    "    title_label = [l+len(x['masked_query']) for l in label]\n",
    "    x['LM_label_idx'] = query_label + title_label\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.apply(test_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair_label(x):\n",
    "    return [5] + x['query_processed'] + [6] + x['changed_product_title'] + [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['original_label'] = train.apply(lambda x: gen_pair_label(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LM_label(x):\n",
    "    return [x['original_label'][i] for i in x['LM_label_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LM_label'] = train.apply(lambda x: get_LM_label(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3156, 1803, 3094, 6, 7, 3993, 7, 2470, 617, 6]\n",
      "[5, 3156, 1803, 3094, 6, 1030, 3993, 4740, 2470, 617, 6]\n",
      "[CLS] bridal shower decorations [SEP] [MASK] alkaline [MASK] aa battery [SEP]\n",
      "[CLS] bridal shower decorations [SEP] panasonic alkalineplus aa battery [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(train['masked_query'].iloc[0] + train['masked_product_title'].iloc[0])\n",
    "print(train['original_label'][0])\n",
    "\n",
    "print(sp.DecodeIds(train['masked_query'].iloc[0] + train['masked_product_title'].iloc[0]))\n",
    "print(sp.DecodeIds(train['original_label'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voca 수\n",
    "vocab_size = len(vocab_list)\n",
    "\n",
    "# 임베딩 벡터의 크기\n",
    "d_model = 512\n",
    "\n",
    "# encoder layer 수\n",
    "num_layers = 6\n",
    "\n",
    "# attentin 수\n",
    "num_heads = 8\n",
    "depth = d_model/num_heads\n",
    "\n",
    "# position embedding max_len\n",
    "# max_len = 150\n",
    "max_len = train.masked_query.map(len).max() + train.masked_product_title.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'masked_query' : tf.ragged.constant(train['masked_query'], dtype=tf.int32, ragged_rank=1),\n",
    "            'masked_product_title' : tf.ragged.constant(train['masked_product_title'], dtype=tf.int32, ragged_rank=1),\n",
    "            'LM_label_idx' : tf.ragged.constant(train['LM_label_idx'], ragged_rank=1),\n",
    "            'NSP_label' : tf.constant(train['NSP_label']),\n",
    "            'LM_label' : tf.ragged.constant(train['LM_label'], dtype=tf.int32, ragged_rank=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(metadata)\n",
    "\n",
    "ds = ds.shuffle(buffer_size=len(train))\n",
    "batchs = 16\n",
    "ds = ds.batch(batchs).repeat()\n",
    "example_batch = next(iter(ds))\n",
    "# example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert_Embedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len, name='Bert_Embedding'):\n",
    "        super(Bert_Embedding, self).__init__(name=name)\n",
    "        self._supports_ragged_inputs = True \n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.Token_Embedding = tf.Variable(tf.random.truncated_normal([self.vocab_size, self.d_model],\n",
    "                                                                      stddev=1.0 / np.sqrt(self.d_model)), \n",
    "                                           trainable=True)\n",
    "        self.Segment_Embedding = tf.Variable(tf.random.truncated_normal([2, self.d_model],\n",
    "                                                                        stddev=1.0 / np.sqrt(self.d_model)), \n",
    "                                             trainable=True)\n",
    "        self.Position_Embedding = tf.Variable(tf.random.truncated_normal([self.max_len, self.d_model],\n",
    "                                                                         stddev=1.0 / np.sqrt(self.d_model)), \n",
    "                                              trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        sentence_pair = tf.concat([inputs['masked_query'], inputs['masked_product_title']], axis=1)\n",
    "        T_embedding = tf.nn.embedding_lookup(self.Token_Embedding, sentence_pair)\n",
    "        \n",
    "        Sa = tf.zeros_like(inputs['masked_query'])\n",
    "        Sb = tf.ones_like(inputs['masked_product_title'])\n",
    "        S_embedding = tf.gather(self.Segment_Embedding, tf.concat([Sa, Sb], axis=1))\n",
    "        \n",
    "        elems = tf.math.reduce_sum(tf.ones_like(sentence_pair), axis=1)\n",
    "        ragged_range = tf.map_fn(tf.range, elems, fn_output_signature=tf.RaggedTensorSpec(shape=[None], dtype=tf.int32))\n",
    "#         P_embedding = tf.ragged.map_flat_values(tf.nn.embedding_lookup, self.Position_Embedding, ragged_range)\n",
    "        P_embedding = tf.gather(self.Position_Embedding, ragged_range)\n",
    "    \n",
    "        return tf.math.add_n([T_embedding, S_embedding, P_embedding])\n",
    "        \n",
    "    def compute_output_shape(self, inputs):\n",
    "        return (inputs['masked_query'].shape[0], None, self.d_model)\n",
    "    \n",
    "bert_embedding = Bert_Embedding(vocab_size, d_model, max_len)\n",
    "result = bert_embedding(example_batch)\n",
    "# result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_Dot_Product_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name='Scaled_Dot_Product_Attention'):\n",
    "        super(Scaled_Dot_Product_Attention, self).__init__(name=name)\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = self.d_model/self.num_heads\n",
    "        self.Q_layer = tf.keras.layers.Dense(units=self.depth)\n",
    "        self.K_layer = tf.keras.layers.Dense(units=self.depth)\n",
    "        self.V_layer = tf.keras.layers.Dense(units=self.depth)\n",
    "    \n",
    "    def QKV_Gen(self, inputs):\n",
    "        Query = tf.ragged.map_flat_values(self.Q_layer, inputs)\n",
    "        Key = tf.ragged.map_flat_values(self.K_layer, inputs)\n",
    "        Value = tf.ragged.map_flat_values(self.V_layer, inputs)\n",
    "        return Query, Key, Value\n",
    "\n",
    "#     def calculate_attention(self, x):\n",
    "#         matmul_qk = tf.matmul(x[0], x[1], transpose_b=True)\n",
    "#         logits = matmul_qk / tf.math.sqrt(depth)\n",
    "#         attention_weights = tf.nn.softmax(logits)\n",
    "#         return tf.matmul(attention_weights, x[2])\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         query, key, value = self.QKV_Gen(inputs)\n",
    "#         attention_value=tf.map_fn(fn=self.calculate_attention, \n",
    "#                                   elems=(query, key, value),\n",
    "#                                   dtype=tf.float32,\n",
    "#                                   fn_output_signature=tf.RaggedTensorSpec(shape=[None, int(self.depth)], ragged_rank=0))\n",
    "#         return attention_value\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value = self.QKV_Gen(inputs)\n",
    "        matmul_qk = tf.ragged.map_flat_values(tf.matmul, query, key, transpose_b=True) \n",
    "        logits = matmul_qk / tf.math.sqrt(self.depth)\n",
    "        attention_weights = tf.ragged.map_flat_values(tf.nn.softmax, logits, axis=-1) \n",
    "        attention_value = tf.ragged.map_flat_values(tf.matmul, attention_weights, value) \n",
    "        return attention_value    \n",
    "    \n",
    "    def compute_output_shape(self, inputs):\n",
    "        return (inputs.shape[0], None, self.d_model)\n",
    "    \n",
    "scaled_Dot_Product_Attention = Scaled_Dot_Product_Attention(d_model, num_heads, name='Scaled_Dot_Product_Attention')\n",
    "qattention_value = scaled_Dot_Product_Attention(result)\n",
    "# attention_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name='multi_head_attention'):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.scaled_dot_product_attention_dict = {}\n",
    "        for i in range(self.num_heads):\n",
    "            self.scaled_dot_product_attention_dict[i] = Scaled_Dot_Product_Attention(self.d_model, self.num_heads)\n",
    "        self.drop_out = tf.keras.layers.Dropout(rate=0.1)\n",
    "        self.norm =  tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.W = tf.Variable(initial_value=w_init(shape=(input_shape[-1], self.d_model), dtype='float32'), trainable=True)\n",
    "        self.b = tf.Variable(initial_value=b_init(shape=(self.d_model,), dtype='float32'), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_value_dict = {}\n",
    "        for i in range(self.num_heads):\n",
    "            attention_value_dict[i] = self.scaled_dot_product_attention_dict[i](inputs)\n",
    "        concat_attention = tf.concat([attention_value_dict[i] for i in range(self.num_heads)], axis=-1)\n",
    "        \n",
    "        outputs = self.drop_out(tf.ragged.map_flat_values(tf.matmul, concat_attention, self.W) + self.b)\n",
    "        return tf.ragged.map_flat_values(self.norm, tf.math.add(outputs, inputs))\n",
    "    \n",
    "    def compute_output_shape(self, inputs):\n",
    "        return (inputs.shape[0], None, self.d_model)\n",
    "    \n",
    "multiheadattention = MultiHeadAttention(d_model, num_heads)\n",
    "multiheadattentionmatrix = multiheadattention(result)\n",
    "# # multiheadattentionmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_and_Norm(tf.keras.layers.Layer):\n",
    "    def __init__(self, name='Add_and_Norm'):\n",
    "        super(Add_and_Norm, self).__init__(name=name)\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.drop_out = tf.keras.layers.Dropout(rate=0.1)\n",
    "        self.norm =  tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs, residual):\n",
    "        outputs = self.drop_out(inputs)\n",
    "        outputs = tf.ragged.map_flat_values(self.norm, tf.math.add(outputs, residual)) \n",
    "        return outputs\n",
    "    \n",
    "    def compute_output_shape(self, inputs):\n",
    "        return (inputs.shape)\n",
    "    \n",
    "# add_and_norm = Add_and_Norm()\n",
    "# norm = add_and_norm(multiheadattentionmatrix, result)\n",
    "# # norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feed_Forward_NN(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, name='Feed_Forward_NN'):\n",
    "        super(Feed_Forward_NN, self).__init__(name=name)\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.d_model = d_model\n",
    "        self.dff = self.d_model*4\n",
    "        self.layer1 = tf.keras.layers.Dense(units=self.dff, activation='relu')\n",
    "        self.layer2 = tf.keras.layers.Dense(units=self.d_model)\n",
    "        self.drop_out = tf.keras.layers.Dropout(rate=0.1)\n",
    "        self.norm =  tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.ragged.map_flat_values(self.layer1, inputs) \n",
    "        x = tf.ragged.map_flat_values(self.layer2, x) \n",
    "        x = self.drop_out(x)\n",
    "        return tf.ragged.map_flat_values(self.norm, tf.math.add(x, inputs)) \n",
    "    \n",
    "# ffnn = FFNN(d_model)\n",
    "# output = ffnn(multiheadattentionmatrix, result)\n",
    "# # output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.models.Model):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, max_len, num_layers, name='BERT'):\n",
    "        super(BERT, self).__init__(name=name)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.max_len = max_len\n",
    "        self.num_layers = num_layers\n",
    "        self.bert_embedding = Bert_Embedding(self.vocab_size, self.d_model, self.max_len)\n",
    "        self.ffnn_dict = {}\n",
    "        self.mha_dict = {}\n",
    "        for i in range(self.num_layers):\n",
    "            self.mha_dict[i] = MultiHeadAttention(self.d_model, self.num_heads, name='MultiHeadAttention_%d'%(i+1))\n",
    "            self.ffnn_dict[i] = Feed_Forward_NN(self.d_model, name='Feed_Forward_NN_%d'%(i+1))\n",
    "        self.lm_layer = tf.keras.layers.Dense(self.vocab_size, activation='softmax', name='lm_layer')\n",
    "        self.nsp_layer = tf.keras.layers.Dense(2, activation='softmax', name='nsp_layer')\n",
    "        self.finetune_layer = tf.keras.layers.Dense(4, activation='softmax', name='finetune_layer')\n",
    "        \n",
    "    def call(self, inputs, mode='pretrain'):\n",
    "        x = self.bert_embedding(inputs)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.mha_dict[i](x)\n",
    "            x = self.ffnn_dict[i](x)\n",
    "        lm_x = tf.map_fn(fn=lambda rt: tf.gather(rt[0], rt[1]), \n",
    "                         elems=(x, inputs['LM_label_idx']),\n",
    "                         dtype=tf.float32,\n",
    "                         fn_output_signature=tf.RaggedTensorSpec(ragged_rank=0))\n",
    "        lm = tf.ragged.map_flat_values(self.lm_layer, lm_x) \n",
    "        nsp = self.nsp_layer(x[:,:1].to_tensor())\n",
    "        pred = self.finetune_layer(x[:,:1].to_tensor())\n",
    "\n",
    "        if mode == 'pretrain':\n",
    "            self.finetune_layer.trainable = False\n",
    "            self.lm_layer.trainable = True\n",
    "            self.nsp_layer.trainable = True\n",
    "            return lm, tf.squeeze(nsp)\n",
    "        elif mode == 'finetune':\n",
    "            self.lm_layer.trainable = False\n",
    "            self.nsp_layer.trainable = False\n",
    "            self.finetune_layer.trainable = True\n",
    "            return tf.squeeze(pred)\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        self.lm_layer.trainable = False\n",
    "        self.nsp_layer.trainable = False\n",
    "        self.finetune_layer.trainable = False\n",
    "        return self.call(inputs, mode='finetune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairwise_loss(y_true, y_pred):\n",
    "    lm_true = y_true['LM_label']   \n",
    "    lm_pred = y_pred[0]\n",
    "    lm_loss = tf.ragged.map_flat_values(tf.keras.losses.sparse_categorical_crossentropy, lm_true, lm_pred)\n",
    "    lm_loss = tf.keras.backend.mean(lm_loss)\n",
    "    \n",
    "    nsp_true = tf.reshape(y_true['NSP_label'], shape=(-1, 1))\n",
    "    nsp_pred = y_pred[1]\n",
    "    nsp_loss = tf.keras.losses.BinaryCrossentropy()(nsp_true, nsp_pred)\n",
    "    return lm_loss + nsp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=9.296924>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = BERT(vocab_size, d_model, num_heads, max_len, num_layers, name='pretrain')\n",
    "\n",
    "Pairwise_loss(y_true=example_batch, y_pred=model(example_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pretrain\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Bert_Embedding (Bert_Embeddi multiple                  1302272   \n",
      "_________________________________________________________________\n",
      "Feed_Forward_NN_1 (Feed_Forw multiple                  526080    \n",
      "_________________________________________________________________\n",
      "Feed_Forward_NN_2 (Feed_Forw multiple                  526080    \n",
      "_________________________________________________________________\n",
      "Feed_Forward_NN_3 (Feed_Forw multiple                  526080    \n",
      "_________________________________________________________________\n",
      "Feed_Forward_NN_4 (Feed_Forw multiple                  526080    \n",
      "_________________________________________________________________\n",
      "Feed_Forward_NN_5 (Feed_Forw multiple                  526080    \n",
      "_________________________________________________________________\n",
      "Feed_Forward_NN_6 (Feed_Forw multiple                  526080    \n",
      "_________________________________________________________________\n",
      "MultiHeadAttention_1 (MultiH multiple                  263680    \n",
      "_________________________________________________________________\n",
      "MultiHeadAttention_2 (MultiH multiple                  263680    \n",
      "_________________________________________________________________\n",
      "MultiHeadAttention_3 (MultiH multiple                  263680    \n",
      "_________________________________________________________________\n",
      "MultiHeadAttention_4 (MultiH multiple                  263680    \n",
      "_________________________________________________________________\n",
      "MultiHeadAttention_5 (MultiH multiple                  263680    \n",
      "_________________________________________________________________\n",
      "MultiHeadAttention_6 (MultiH multiple                  263680    \n",
      "_________________________________________________________________\n",
      "lm_layer (Dense)             multiple                  1285000   \n",
      "_________________________________________________________________\n",
      "nsp_layer (Dense)            multiple                  514       \n",
      "_________________________________________________________________\n",
      "finetune_layer (Dense)       multiple                  1028      \n",
      "=================================================================\n",
      "Total params: 7,327,374\n",
      "Trainable params: 7,326,346\n",
      "Non-trainable params: 1,028\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "print_step = 10\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 0: 9.13530\n",
      "Seen so far: 16 train samples, learning rate: 0.0100\n",
      "time : 1.3732144832611084\n",
      "Training loss at step 1: 16.27972\n",
      "Seen so far: 32 train samples, learning rate: 0.0100\n",
      "time : 0.9264662265777588\n",
      "Training loss at step 2: 16.20086\n",
      "Seen so far: 48 train samples, learning rate: 0.0100\n",
      "time : 0.9144794940948486\n",
      "Training loss at step 3: 16.59946\n",
      "Seen so far: 64 train samples, learning rate: 0.0100\n",
      "time : 0.8665027618408203\n",
      "Training loss at step 4: 18.50201\n",
      "Seen so far: 80 train samples, learning rate: 0.0100\n",
      "time : 1.0593924522399902\n",
      "Training loss at step 5: 19.24283\n",
      "Seen so far: 96 train samples, learning rate: 0.0100\n",
      "time : 0.9444601535797119\n",
      "Training loss at step 6: 20.04819\n",
      "Seen so far: 112 train samples, learning rate: 0.0100\n",
      "time : 0.9934334754943848\n",
      "Training loss at step 7: 20.68473\n",
      "Seen so far: 128 train samples, learning rate: 0.0100\n",
      "time : 1.0294110774993896\n",
      "Training loss at step 8: 22.00525\n",
      "Seen so far: 144 train samples, learning rate: 0.0100\n",
      "time : 0.8834934234619141\n",
      "Training loss at step 9: 20.80902\n",
      "Seen so far: 160 train samples, learning rate: 0.0100\n",
      "time : 1.011420726776123\n",
      "Training loss at step 10: 21.94773\n",
      "Seen so far: 176 train samples, learning rate: 0.0100\n",
      "time : 0.9794378280639648\n",
      "Training loss at step 11: 21.28675\n",
      "Seen so far: 192 train samples, learning rate: 0.0100\n",
      "time : 0.8425171375274658\n",
      "Training loss at step 12: 21.17448\n",
      "Seen so far: 208 train samples, learning rate: 0.0100\n",
      "time : 0.905484676361084\n",
      "Training loss at step 13: 20.96898\n",
      "Seen so far: 224 train samples, learning rate: 0.0100\n",
      "time : 0.9364650249481201\n",
      "Training loss at step 14: 21.20625\n",
      "Seen so far: 240 train samples, learning rate: 0.0100\n",
      "time : 0.910477876663208\n",
      "Training loss at step 15: 21.61801\n",
      "Seen so far: 256 train samples, learning rate: 0.0100\n",
      "time : 0.8145356178283691\n",
      "Training loss at step 16: 21.69696\n",
      "Seen so far: 272 train samples, learning rate: 0.0100\n",
      "time : 0.7865493297576904\n",
      "Training loss at step 17: 20.29027\n",
      "Seen so far: 288 train samples, learning rate: 0.0100\n",
      "time : 0.9224717617034912\n",
      "Training loss at step 18: 20.81026\n",
      "Seen so far: 304 train samples, learning rate: 0.0100\n",
      "time : 0.9884369373321533\n",
      "Training loss at step 19: 20.05767\n",
      "Seen so far: 320 train samples, learning rate: 0.0100\n",
      "time : 0.8265252113342285\n",
      "Training loss at step 20: 21.04623\n",
      "Seen so far: 336 train samples, learning rate: 0.0100\n",
      "time : 0.9944295883178711\n",
      "Training loss at step 21: 22.19797\n",
      "Seen so far: 352 train samples, learning rate: 0.0100\n",
      "time : 0.916475772857666\n",
      "Training loss at step 22: 21.08544\n",
      "Seen so far: 368 train samples, learning rate: 0.0100\n",
      "time : 0.8894915580749512\n",
      "Training loss at step 23: 20.66501\n",
      "Seen so far: 384 train samples, learning rate: 0.0100\n",
      "time : 0.867501974105835\n",
      "Training loss at step 24: 21.24556\n",
      "Seen so far: 400 train samples, learning rate: 0.0100\n",
      "time : 0.8545122146606445\n",
      "Training loss at step 25: 21.49028\n",
      "Seen so far: 416 train samples, learning rate: 0.0100\n",
      "time : 0.8035402297973633\n",
      "Training loss at step 26: 21.69415\n",
      "Seen so far: 432 train samples, learning rate: 0.0100\n",
      "time : 0.9264700412750244\n",
      "Training loss at step 27: 21.30900\n",
      "Seen so far: 448 train samples, learning rate: 0.0100\n",
      "time : 0.8515114784240723\n",
      "Training loss at step 28: 22.10286\n",
      "Seen so far: 464 train samples, learning rate: 0.0100\n",
      "time : 0.8285260200500488\n",
      "Training loss at step 29: 21.18391\n",
      "Seen so far: 480 train samples, learning rate: 0.0100\n",
      "time : 0.869504451751709\n",
      "Training loss at step 30: 20.30570\n",
      "Seen so far: 496 train samples, learning rate: 0.0100\n",
      "time : 0.9124772548675537\n",
      "Training loss at step 31: 22.74827\n",
      "Seen so far: 512 train samples, learning rate: 0.0100\n",
      "time : 0.7595629692077637\n",
      "Training loss at step 32: 20.85352\n",
      "Seen so far: 528 train samples, learning rate: 0.0100\n",
      "time : 0.9084811210632324\n",
      "Training loss at step 33: 21.71088\n",
      "Seen so far: 544 train samples, learning rate: 0.0100\n",
      "time : 0.8545114994049072\n",
      "Training loss at step 34: 21.30063\n",
      "Seen so far: 560 train samples, learning rate: 0.0100\n",
      "time : 0.881493330001831\n",
      "Training loss at step 35: 20.80312\n",
      "Seen so far: 576 train samples, learning rate: 0.0100\n",
      "time : 0.9294676780700684\n",
      "Training loss at step 36: 20.75459\n",
      "Seen so far: 592 train samples, learning rate: 0.0100\n",
      "time : 1.0024266242980957\n",
      "Training loss at step 37: 20.38791\n",
      "Seen so far: 608 train samples, learning rate: 0.0100\n",
      "time : 1.0194189548492432\n",
      "Training loss at step 38: 22.90079\n",
      "Seen so far: 624 train samples, learning rate: 0.0100\n",
      "time : 0.9274682998657227\n",
      "Training loss at step 39: 20.99366\n",
      "Seen so far: 640 train samples, learning rate: 0.0100\n",
      "time : 1.0893752574920654\n",
      "Training loss at step 40: 20.96024\n",
      "Seen so far: 656 train samples, learning rate: 0.0100\n",
      "time : 1.0434036254882812\n",
      "Training loss at step 41: 22.10326\n",
      "Seen so far: 672 train samples, learning rate: 0.0100\n",
      "time : 0.9644467830657959\n",
      "Training loss at step 42: 20.55921\n",
      "Seen so far: 688 train samples, learning rate: 0.0100\n",
      "time : 1.230297327041626\n",
      "Training loss at step 43: 19.68900\n",
      "Seen so far: 704 train samples, learning rate: 0.0100\n",
      "time : 0.9684443473815918\n",
      "Training loss at step 44: 21.34229\n",
      "Seen so far: 720 train samples, learning rate: 0.0100\n",
      "time : 0.9194717407226562\n",
      "Training loss at step 45: 19.84356\n",
      "Seen so far: 736 train samples, learning rate: 0.0100\n",
      "time : 1.1813251972198486\n",
      "Training loss at step 46: 21.15165\n",
      "Seen so far: 752 train samples, learning rate: 0.0100\n",
      "time : 0.8964855670928955\n",
      "Training loss at step 47: 22.36811\n",
      "Seen so far: 768 train samples, learning rate: 0.0100\n",
      "time : 0.9504568576812744\n",
      "Training loss at step 48: 21.99396\n",
      "Seen so far: 784 train samples, learning rate: 0.0100\n",
      "time : 0.9104781150817871\n",
      "Training loss at step 49: 22.73688\n",
      "Seen so far: 800 train samples, learning rate: 0.0100\n",
      "time : 1.224299430847168\n",
      "Training loss at step 50: 21.12923\n",
      "Seen so far: 816 train samples, learning rate: 0.0100\n",
      "time : 1.013420820236206\n",
      "Training loss at step 51: 21.30311\n",
      "Seen so far: 832 train samples, learning rate: 0.0100\n",
      "time : 0.9474577903747559\n",
      "Training loss at step 52: 21.31655\n",
      "Seen so far: 848 train samples, learning rate: 0.0100\n",
      "time : 0.8974883556365967\n",
      "Training loss at step 53: 20.79496\n",
      "Seen so far: 864 train samples, learning rate: 0.0100\n",
      "time : 0.9674472808837891\n",
      "Training loss at step 54: 21.87640\n",
      "Seen so far: 880 train samples, learning rate: 0.0100\n",
      "time : 1.088378667831421\n",
      "Training loss at step 55: 22.32236\n",
      "Seen so far: 896 train samples, learning rate: 0.0100\n",
      "time : 0.926469087600708\n",
      "Training loss at step 56: 19.90070\n",
      "Seen so far: 912 train samples, learning rate: 0.0100\n",
      "time : 0.916475772857666\n",
      "Training loss at step 57: 21.88170\n",
      "Seen so far: 928 train samples, learning rate: 0.0100\n",
      "time : 1.0044245719909668\n",
      "Training loss at step 58: 21.32681\n",
      "Seen so far: 944 train samples, learning rate: 0.0100\n",
      "time : 1.0084218978881836\n",
      "Training loss at step 59: 21.10264\n",
      "Seen so far: 960 train samples, learning rate: 0.0100\n",
      "time : 0.8375205993652344\n",
      "Training loss at step 60: 22.75496\n",
      "Seen so far: 976 train samples, learning rate: 0.0100\n",
      "time : 0.8545126914978027\n",
      "Training loss at step 61: 20.60801\n",
      "Seen so far: 992 train samples, learning rate: 0.0100\n",
      "time : 0.9264688491821289\n",
      "Training loss at step 62: 20.76439\n",
      "Seen so far: 1008 train samples, learning rate: 0.0100\n",
      "time : 0.961449384689331\n",
      "Training loss at step 63: 21.18390\n",
      "Seen so far: 1024 train samples, learning rate: 0.0100\n",
      "time : 0.905482292175293\n",
      "Training loss at step 64: 21.26617\n",
      "Seen so far: 1040 train samples, learning rate: 0.0100\n",
      "time : 0.9164743423461914\n",
      "Training loss at step 65: 22.02693\n",
      "Seen so far: 1056 train samples, learning rate: 0.0100\n",
      "time : 1.0853793621063232\n",
      "Training loss at step 66: 22.34003\n",
      "Seen so far: 1072 train samples, learning rate: 0.0100\n",
      "time : 1.1893203258514404\n",
      "Training loss at step 67: 20.73162\n",
      "Seen so far: 1088 train samples, learning rate: 0.0100\n",
      "time : 0.967444896697998\n",
      "Training loss at step 68: 21.68413\n",
      "Seen so far: 1104 train samples, learning rate: 0.0100\n",
      "time : 1.0963733196258545\n",
      "Training loss at step 69: 21.81393\n",
      "Seen so far: 1120 train samples, learning rate: 0.0100\n",
      "time : 1.1483440399169922\n",
      "Training loss at step 70: 21.10231\n",
      "Seen so far: 1136 train samples, learning rate: 0.0100\n",
      "time : 1.2742679119110107\n",
      "Training loss at step 71: 19.51868\n",
      "Seen so far: 1152 train samples, learning rate: 0.0100\n",
      "time : 0.9924311637878418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 72: 21.80588\n",
      "Seen so far: 1168 train samples, learning rate: 0.0100\n",
      "time : 1.232295036315918\n",
      "Training loss at step 73: 21.41245\n",
      "Seen so far: 1184 train samples, learning rate: 0.0100\n",
      "time : 1.1493420600891113\n",
      "Training loss at step 74: 21.90866\n",
      "Seen so far: 1200 train samples, learning rate: 0.0100\n",
      "time : 1.0194172859191895\n",
      "Training loss at step 75: 21.51030\n",
      "Seen so far: 1216 train samples, learning rate: 0.0100\n",
      "time : 1.0184180736541748\n",
      "Training loss at step 76: 19.99257\n",
      "Seen so far: 1232 train samples, learning rate: 0.0100\n",
      "time : 0.9614520072937012\n",
      "Training loss at step 77: 21.90478\n",
      "Seen so far: 1248 train samples, learning rate: 0.0100\n",
      "time : 0.9934313297271729\n",
      "Training loss at step 78: 20.63989\n",
      "Seen so far: 1264 train samples, learning rate: 0.0100\n",
      "time : 0.9484570026397705\n",
      "Training loss at step 79: 21.95700\n",
      "Seen so far: 1280 train samples, learning rate: 0.0100\n",
      "time : 0.9804389476776123\n",
      "Training loss at step 80: 21.99377\n",
      "Seen so far: 1296 train samples, learning rate: 0.0100\n",
      "time : 1.0094237327575684\n",
      "Training loss at step 81: 20.07546\n",
      "Seen so far: 1312 train samples, learning rate: 0.0100\n",
      "time : 1.2702710628509521\n",
      "Training loss at step 82: 20.67566\n",
      "Seen so far: 1328 train samples, learning rate: 0.0100\n",
      "time : 1.0513992309570312\n",
      "Training loss at step 83: 21.00348\n",
      "Seen so far: 1344 train samples, learning rate: 0.0100\n",
      "time : 1.1073668003082275\n",
      "Training loss at step 84: 19.67732\n",
      "Seen so far: 1360 train samples, learning rate: 0.0100\n",
      "time : 1.1273565292358398\n",
      "Training loss at step 85: 22.08813\n",
      "Seen so far: 1376 train samples, learning rate: 0.0100\n",
      "time : 0.9144761562347412\n",
      "Training loss at step 86: 21.10973\n",
      "Seen so far: 1392 train samples, learning rate: 0.0100\n",
      "time : 1.0813801288604736\n",
      "Training loss at step 87: 20.02277\n",
      "Seen so far: 1408 train samples, learning rate: 0.0100\n",
      "time : 1.1733300685882568\n",
      "Training loss at step 88: 21.66290\n",
      "Seen so far: 1424 train samples, learning rate: 0.0100\n",
      "time : 1.0873761177062988\n",
      "Training loss at step 89: 20.47593\n",
      "Seen so far: 1440 train samples, learning rate: 0.0100\n",
      "time : 1.1213603019714355\n",
      "Training loss at step 90: 23.05221\n",
      "Seen so far: 1456 train samples, learning rate: 0.0100\n",
      "time : 0.9414613246917725\n",
      "Training loss at step 91: 20.58370\n",
      "Seen so far: 1472 train samples, learning rate: 0.0100\n",
      "time : 1.003425121307373\n",
      "Training loss at step 92: 20.31425\n",
      "Seen so far: 1488 train samples, learning rate: 0.0100\n",
      "time : 0.9134833812713623\n",
      "Training loss at step 93: 21.17127\n",
      "Seen so far: 1504 train samples, learning rate: 0.0100\n",
      "time : 1.016413927078247\n",
      "Training loss at step 94: 20.97923\n",
      "Seen so far: 1520 train samples, learning rate: 0.0100\n",
      "time : 0.9844362735748291\n",
      "Training loss at step 95: 20.99533\n",
      "Seen so far: 1536 train samples, learning rate: 0.0100\n",
      "time : 1.0264122486114502\n",
      "Training loss at step 96: 20.61042\n",
      "Seen so far: 1552 train samples, learning rate: 0.0100\n",
      "time : 1.0603928565979004\n",
      "Training loss at step 97: 21.40357\n",
      "Seen so far: 1568 train samples, learning rate: 0.0100\n",
      "time : 1.0214145183563232\n",
      "Training loss at step 98: 19.85255\n",
      "Seen so far: 1584 train samples, learning rate: 0.0100\n",
      "time : 1.0124220848083496\n",
      "Training loss at step 99: 21.15025\n",
      "Seen so far: 1600 train samples, learning rate: 0.0100\n",
      "time : 1.2382948398590088\n",
      "Training loss at step 100: 20.65259\n",
      "Seen so far: 1616 train samples, learning rate: 0.0100\n",
      "time : 1.1653308868408203\n",
      "Training loss at step 101: 20.31807\n",
      "Seen so far: 1632 train samples, learning rate: 0.0100\n",
      "time : 1.0234153270721436\n",
      "Training loss at step 102: 20.75173\n",
      "Seen so far: 1648 train samples, learning rate: 0.0100\n",
      "time : 1.2013137340545654\n",
      "Training loss at step 103: 20.06641\n",
      "Seen so far: 1664 train samples, learning rate: 0.0100\n",
      "time : 0.9214715957641602\n",
      "Training loss at step 104: 21.30817\n",
      "Seen so far: 1680 train samples, learning rate: 0.0100\n",
      "time : 0.9874353408813477\n",
      "Training loss at step 105: 21.66348\n",
      "Seen so far: 1696 train samples, learning rate: 0.0100\n",
      "time : 1.3122496604919434\n",
      "Training loss at step 106: 22.18558\n",
      "Seen so far: 1712 train samples, learning rate: 0.0100\n",
      "time : 0.9644491672515869\n",
      "Training loss at step 107: 20.98523\n",
      "Seen so far: 1728 train samples, learning rate: 0.0100\n",
      "time : 0.8555097579956055\n",
      "Training loss at step 108: 21.73750\n",
      "Seen so far: 1744 train samples, learning rate: 0.0100\n",
      "time : 1.0314102172851562\n",
      "Training loss at step 109: 21.59006\n",
      "Seen so far: 1760 train samples, learning rate: 0.0100\n",
      "time : 1.0503993034362793\n",
      "Training loss at step 110: 20.91431\n",
      "Seen so far: 1776 train samples, learning rate: 0.0100\n",
      "time : 0.9374642372131348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    343\u001b[0m       return add_eager_fallback(\n\u001b[1;32m--> 344\u001b[1;33m           x, y, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    345\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_eager_fallback\u001b[1;34m(x, y, name, ctx)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_eager_fallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m   \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_inputs_T\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_inputs_T\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[1;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[0;32m    262\u001b[0m           ops.convert_to_tensor(\n\u001b[1;32m--> 263\u001b[1;33m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[0;32m    264\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 264\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: TypeError: object of type 'RaggedTensor' has no len()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-39662dd0f03b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pretrain'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPairwise_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-7ca396dc6597>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mode)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmha_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffnn_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         lm_x = tf.map_fn(fn=lambda rt: tf.gather(rt[0], rt[1]), \n\u001b[0;32m     25\u001b[0m                          \u001b[0melems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LM_label_idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-83e253cbe600>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mragged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_flat_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mragged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_flat_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# ffnn = FFNN(d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m       result = _dispatch.dispatch(\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[0madd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m           )\n\u001b[0;32m    351\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(op, args, kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \"\"\"\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDISPATCH_ATTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_dispatch.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m           x, bcast_shape, broadcast_inner_dimensions=False)\n\u001b[0;32m    222\u001b[0m       y = ragged_tensor_shape.broadcast_to(\n\u001b[1;32m--> 223\u001b[1;33m           y, bcast_shape, broadcast_inner_dimensions=False)\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_values\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ragged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor_shape.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(rt_input, shape, broadcast_inner_dimensions)\u001b[0m\n\u001b[0;32m    501\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     return _broadcast_to_ragged_shape(rt_input, shape,\n\u001b[1;32m--> 503\u001b[1;33m                                       broadcast_inner_dimensions)\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor_shape.py\u001b[0m in \u001b[0;36m_broadcast_to_ragged_shape\u001b[1;34m(rt_input, dst_shape, broadcast_inner_dimensions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Incompatible with shape: ragged rank mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m   \u001b[0msrc_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRaggedTensorDynamicShape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m   \u001b[0msrc_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_to_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor_shape.py\u001b[0m in \u001b[0;36mfrom_tensor\u001b[1;34m(cls, rt_input, dim_size_dtype)\u001b[0m\n\u001b[0;32m    187\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         partitioned_dim_sizes = (\n\u001b[1;32m--> 189\u001b[1;33m             (rt_input.nrows(),) + rt_input.nested_row_lengths())\n\u001b[0m\u001b[0;32m    190\u001b[0m         return RaggedTensorDynamicShape(\n\u001b[0;32m    191\u001b[0m             \u001b[0mpartitioned_dim_sizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor.py\u001b[0m in \u001b[0;36mnested_row_lengths\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1185\u001b[0m       \u001b[0mrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRaggedTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m         \u001b[0mrt_nested_row_lengths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m         \u001b[0mrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_nested_row_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor.py\u001b[0m in \u001b[0;36mrow_lengths\u001b[1;34m(self, axis, name)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_row_partition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RaggedRowLengths\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\row_partition.py\u001b[0m in \u001b[0;36mrow_lengths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_row_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[0msplits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_row_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1194\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10315\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10316\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10317\u001b[1;33m         \"new_axis_mask\", new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[0;32m  10318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10319\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_sum = 0\n",
    "start = time.time()\n",
    "for step, batch_train in enumerate(ds):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(batch_train, mode='pretrain')\n",
    "        loss_value = Pairwise_loss(y_true=batch_train, y_pred=logits)\n",
    "        loss_sum += loss_value \n",
    "        \n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    if step % print_step == 0:\n",
    "        current_loss_average = float(loss_sum)/print_step\n",
    "        if step ==0:\n",
    "            current_loss_average = loss_sum\n",
    "        \n",
    "        loss_sum = 0\n",
    "        print(\"Training loss at step %d: %.5f\"% (step, current_loss_average))\n",
    "        print(\"Seen so far: %s train samples, learning rate: %.4f\" % ((step + 1) * batchs, learning_rate))\n",
    "        print(\"time :\", time.time() - start)\n",
    "        start = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_query = tf.keras.layers.Input(shape=(None,), batch_size=16, dtype=tf.int32, ragged=True)\n",
    "# inputs_product_title = tf.keras.layers.Input(shape=(None,), batch_size=16, dtype=tf.int32, ragged=True)\n",
    "# inputs = {'masked_query':inputs_query,\n",
    "#           'masked_product_title':inputs_product_title}\n",
    "\n",
    "# x = Bert_Embedding(vocab_size, d_model, max_len)(inputs)\n",
    "\n",
    "# x = MultiHeadAttention(d_model, num_heads)(x)\n",
    "# x = Feed_Forward_NN(d_model)(x)\n",
    "\n",
    "# x = MultiHeadAttention(d_model, num_heads)(x)\n",
    "# x = Feed_Forward_NN(d_model)(x)\n",
    "\n",
    "# x = MultiHeadAttention(d_model, num_heads)(x)\n",
    "# x = Feed_Forward_NN(d_model)(x)\n",
    "\n",
    "# x = MultiHeadAttention(d_model, num_heads)(x)\n",
    "# x = Feed_Forward_NN(d_model)(x)\n",
    "\n",
    "# x = MultiHeadAttention(d_model, num_heads)(x)\n",
    "# x = Feed_Forward_NN(d_model)(x)\n",
    "\n",
    "# x = MultiHeadAttention(d_model, num_heads)(x)\n",
    "# x = Feed_Forward_NN(d_model)(x)\n",
    "\n",
    "# lm = tf.ragged.map_flat_values(tf.keras.layers.Dense(vocab_size, activation='softmax'), x) \n",
    "# nsp = tf.keras.layers.Dense(2, activation='softmax')(x[:,:1].to_tensor())\n",
    "# pred = tf.keras.layers.Dense(4, activation='softmax')(x[:,:1].to_tensor())\n",
    "\n",
    "# lm_true = y_true['LM_label']   \n",
    "# lm_pred = y_pred[0]\n",
    "# lm_loss = tf.ragged.map_flat_values(tf.keras.losses.sparse_categorical_crossentropy, lm_true, lm_pred)\n",
    "# lm_loss = tf.keras.backend.mean(lm_loss)\n",
    "\n",
    "# nsp_true = tf.reshape(y_true['NSP_label'], shape=(-1, 1))\n",
    "# nsp_pred = y_pred[1]\n",
    "\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit(data, labels)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 312,
   "position": {
    "height": "40px",
    "left": "726px",
    "right": "20px",
    "top": "10px",
    "width": "597px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
