{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T01:57:29.378263Z",
     "start_time": "2020-08-03T01:57:07.327898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "import random\n",
    "from ast import literal_eval\n",
    "\n",
    "from utility.utility import generate_pairwise_dataset\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:12.607Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, input_dims=5, **kwargs):\n",
    "        super(Dense, self).__init__(name='Linear', **kwargs)\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.units = units\n",
    "        self.input_dims = input_dims\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer = tf.keras.initializers.he_normal()\n",
    "        self.w = self.add_weight(\n",
    "            shape=(self.input_dims, self.units),\n",
    "            initializer=initializer,\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), \n",
    "            initializer=tf.zeros_initializer, \n",
    "            trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.ragged.map_flat_values(tf.matmul, inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:12.834Z"
    }
   },
   "outputs": [],
   "source": [
    "class Word_Matching_Network(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Word_Matching_Network, self).__init__(name='Word_Matching_Network')\n",
    "        self._supports_ragged_inputs = True        \n",
    "        self.Layer1 = Dense(5, input_dims=30)\n",
    "        self.BN1 = tf.keras.layers.BatchNormalization()\n",
    "        self.Layer2 = Dense(5, input_dims=5)\n",
    "        self.BN2 = tf.keras.layers.BatchNormalization()\n",
    "        self.Layer3 = Dense(1, input_dims=5)\n",
    "        self.BN3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.Layer1(inputs)\n",
    "        x = tf.ragged.map_flat_values(tf.nn.relu, x)\n",
    "        x = tf.ragged.map_flat_values(self.BN1, x)\n",
    "        \n",
    "        x = self.Layer2(x)\n",
    "        x = tf.ragged.map_flat_values(tf.nn.relu, x)\n",
    "        x = tf.ragged.map_flat_values(self.BN2, x)\n",
    "        \n",
    "        x = self.Layer3(x)\n",
    "        x = tf.ragged.map_flat_values(tf.nn.relu, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.067Z"
    }
   },
   "outputs": [],
   "source": [
    "class Gating_Network(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Gating_Network, self).__init__()\n",
    "        self._supports_ragged_inputs = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "        self.w = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            name='Gating_weight',\n",
    "            initializer=initializer,\n",
    "            trainable=True)\n",
    "\n",
    "#     def ragged_softmax(self, logits):\n",
    "#         print(logits)\n",
    "#         numerator = tf.exp(logits)\n",
    "#         print(numerator)\n",
    "#         denominator = tf.reduce_sum(numerator, axis=1)\n",
    "#         print(denominator)\n",
    "#         softmax = tf.math.divide_no_nan(numerator, tf.reshape(denominator, shape=(logits.shape[0], -1)))\n",
    "#         return softmax\n",
    "        \n",
    "    def call(self, idf):\n",
    "        g = tf.math.multiply(idf, self.w)\n",
    "        softmax = tf.ragged.map_flat_values(tf.nn.softmax, g)\n",
    "#         softmax = self.ragged_softmax(g)\n",
    "        return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.267Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score_Aggregation(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Score_Aggregation, self).__init__(name='Score_Aggregation')\n",
    "        self._supports_ragged_inputs = True\n",
    "\n",
    "    def call(self, Z, g):\n",
    "        score = tf.ragged.map_flat_values(tf.reshape, Z, shape=(-1, ))\n",
    "        gating = g\n",
    "        s_g_sum = tf.math.multiply(gating, score)\n",
    "        return tf.math.reduce_sum(s_g_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.492Z"
    }
   },
   "outputs": [],
   "source": [
    "class DRMM(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DRMM, self).__init__(name='DRMM')\n",
    "        self._supports_ragged_inputs = True\n",
    "        self.Word_Matching_Network = Word_Matching_Network()\n",
    "        self.Gating_Network = Gating_Network()\n",
    "        self.Score_Aggregation = Score_Aggregation()\n",
    "\n",
    "    def call(self, inputs, idf):\n",
    "        Z = self.Word_Matching_Network(inputs)\n",
    "        G = self.Gating_Network(idf)\n",
    "        score = self.Score_Aggregation(Z, G)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pairwise_DRMM(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Pairwise_DRMM, self).__init__(name='Pairwise_DRMM')\n",
    "        self.drmm = DRMM()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        positive_hist = inputs['positive_hist']\n",
    "        negative_hist = inputs['negative_hist']\n",
    "        query_idf = inputs['query_idf']\n",
    "        \n",
    "        positive = self.drmm(positive_hist, query_idf)\n",
    "        negative = self.drmm(negative_hist, query_idf)\n",
    "        \n",
    "        return tf.concat([positive, negative], axis=0) \n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        hist = inputs['hist']\n",
    "        query_idf = inputs['query_idf']\n",
    "        score = self.drmm(hist, query_idf)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:13.707Z"
    }
   },
   "outputs": [],
   "source": [
    "def Pairwise_ranking_loss(y_true, y_pred):\n",
    "    '''\n",
    "    ignore y_true\n",
    "    '''\n",
    "    positive_score = tf.keras.layers.Lambda(lambda x: x[:len(x)//2], output_shape= (1,))(y_pred)\n",
    "    negative_score = tf.keras.layers.Lambda(lambda x: x[len(x)//2:], output_shape= (1,))(y_pred)\n",
    "\n",
    "    return tf.keras.backend.mean(tf.math.maximum(0., 1 - positive_score + negative_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(rel_pred, p=None, form=\"linear\"):\n",
    "    if p==None:\n",
    "        p = len(rel_pred)\n",
    "    if p > len(rel_pred):\n",
    "        rel_pred = np.append(rel_pred, [0]*(p - len(rel_pred)))\n",
    "    \n",
    "    rel_true = np.sort(rel_pred)[::-1]\n",
    "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
    "\n",
    "    if form == \"linear\":\n",
    "        idcg = np.sum(rel_true[:p] * discount)\n",
    "        dcg = np.sum(rel_pred[:p] * discount)\n",
    "    elif form == \"exponential\" or form == \"exp\":\n",
    "        idcg = np.sum([2**x - 1 for x in rel_true[:p]] * discount)\n",
    "        dcg = np.sum([2**x - 1 for x in rel_pred[:p]] * discount)\n",
    "    else:\n",
    "        raise ValueError(\"Only supported for two formula, 'linear' or 'exp'\")\n",
    "    \n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/paccr_drmm_bert_test_all.csv', converters={\"query_idf\"          : literal_eval,\n",
    "                                                                      \"idf_softmax\"        : literal_eval,\n",
    "                                                                      \"sim_matrix\"         : literal_eval,\n",
    "                                                                      \"query_token\"        : literal_eval,\n",
    "                                                                      \"product_title_token\": literal_eval,\n",
    "                                                                      \"token_ids\"          : literal_eval,\n",
    "                                                                      \"drmm_hist\"          : literal_eval,\n",
    "                                                                      'token'              : literal_eval})\n",
    "\n",
    "test['binary_relevance'] = test['median_relevance'].apply(lambda x: 0 if x <= 2 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd82d253f5c349fabeb3a7005288c475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = generate_pairwise_dataset(test)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/paccr_drmm_.csv', converters={\"positive_hist\": literal_eval, \n",
    "#                                                        \"negative_hist\": literal_eval,\n",
    "#                                                        \"query_idf\": literal_eval})\n",
    "\n",
    "\n",
    "# df = df[['query_len', 'query_preprocessed', 'positive_hist', 'negative_hist', 'query_idf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('./data/paccr_drmm_test.csv', converters={\"hist\": literal_eval,\n",
    "#                                                              \"query_idf\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_q = set(random.sample(list(df['query'].unique()), 40))\n",
    "train_q = set(df['query'].unique()) - dev_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_q = set(random.sample(list(df['query_preprocessed'].unique()), 40))\n",
    "# train_q = set(df['query_preprocessed'].unique()) - dev_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([df.groupby('query').get_group(name) for name in train_q]).sample(frac=1).reset_index(drop=True)\n",
    "dev = pd.concat([df.groupby('query').get_group(name) for name in dev_q]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([df.groupby('query_preprocessed').get_group(name) for name in train_q]).sample(frac=1).reset_index(drop=True)\n",
    "# dev = pd.concat([df.groupby('query_preprocessed').get_group(name) for name in dev_q]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'query_idf'          : tf.ragged.constant(train['query_idf'], dtype=tf.float32, ragged_rank=1, name='query_idf'),\n",
    "            'positive_hist'      : tf.ragged.constant(train['drmm_hist_P'], dtype=tf.float32, ragged_rank=1, name='positive_hist'),\n",
    "            'negative_hist'      : tf.ragged.constant(train['drmm_hist_N'], dtype=tf.float32, ragged_rank=1, name='negative_hist')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dev = {'query_idf'          : tf.ragged.constant(dev['query_idf'], dtype=tf.float32, ragged_rank=1, name='query_idf'),\n",
    "                'positive_hist'      : tf.ragged.constant(dev['drmm_hist_P'], dtype=tf.float32, ragged_rank=1, name='positive_hist'),\n",
    "                'negative_hist'      : tf.ragged.constant(dev['drmm_hist_N'], dtype=tf.float32, ragged_rank=1, name='negative_hist')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = {'query_idf': tf.ragged.constant(train.query_idf, dtype=tf.float32, ragged_rank=1),\n",
    "#             'positive_hist': tf.ragged.constant(train.positive_hist, dtype=tf.float32, ragged_rank=1),\n",
    "#             'negative_hist': tf.ragged.constant(train.negative_hist, dtype=tf.float32, ragged_rank=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_dev = {'query_idf': tf.ragged.constant(dev.query_idf, dtype=tf.float32, ragged_rank=1),\n",
    "#                 'positive_hist': tf.ragged.constant(dev.positive_hist, dtype=tf.float32, ragged_rank=1),\n",
    "#                 'negative_hist': tf.ragged.constant(dev.negative_hist, dtype=tf.float32, ragged_rank=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(metadata)\n",
    "ds = ds.shuffle(buffer_size=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = 128\n",
    "ds = ds.batch(batchs).repeat()\n",
    "example_batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {'negative_hist':tf.keras.Input(shape=(None, 30), ragged=True), \n",
    "#           'positive_hist':tf.keras.Input(shape=(None, 30), ragged=True), \n",
    "#           'query_idf':tf.keras.Input(shape=(None,), ragged=True)}\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "# output = Pairwise_DRMM()(inputs)\n",
    "\n",
    "# model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# total_epoch_count = 100\n",
    "# batch_size = 256\n",
    "# learning_rate= .1\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=learning_rate),\n",
    "#               loss=Pairwise_ranking_loss)\n",
    "\n",
    "# model.fit(x=metadata, y=tf.constant([0.]*len(train)), \n",
    "#           validation_data=(metadata_dev, tf.constant([0.]*len(dev))),\n",
    "#           shuffle=True,\n",
    "#           epochs=total_epoch_count,\n",
    "#           batch_size=batch_size,\n",
    "#           callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T01:57:25.640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.99999857, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Pairwise_DRMM()\n",
    "learning_rate = .1\n",
    "print_step = 1\n",
    "n=20\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "print(Pairwise_ranking_loss(y_true=None, y_pred=model(example_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwon\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 0: 0.99992, dev_loss : 1.00000, nDCG@20 : 0.74149\n",
      "Seen so far: 128 train samples, learning rate: 0.1000\n",
      "Training loss at step 1: 0.99977, dev_loss : 1.00000, nDCG@20 : 0.74148\n",
      "Seen so far: 256 train samples, learning rate: 0.1000\n",
      "Training loss at step 2: 0.99989, dev_loss : 1.00000, nDCG@20 : 0.74148\n",
      "Seen so far: 384 train samples, learning rate: 0.1000\n",
      "Training loss at step 3: 0.99986, dev_loss : 1.00000, nDCG@20 : 0.74080\n",
      "Seen so far: 512 train samples, learning rate: 0.1000\n",
      "Training loss at step 4: 0.99971, dev_loss : 1.00000, nDCG@20 : 0.74080\n",
      "Seen so far: 640 train samples, learning rate: 0.1000\n",
      "Training loss at step 5: 1.00001, dev_loss : 1.00000, nDCG@20 : 0.74081\n",
      "Seen so far: 768 train samples, learning rate: 0.1000\n",
      "Training loss at step 6: 0.99997, dev_loss : 1.00000, nDCG@20 : 0.74080\n",
      "Seen so far: 896 train samples, learning rate: 0.1000\n",
      "Training loss at step 7: 0.99983, dev_loss : 1.00000, nDCG@20 : 0.74081\n",
      "Seen so far: 1024 train samples, learning rate: 0.1000\n",
      "Training loss at step 8: 0.99975, dev_loss : 1.00000, nDCG@20 : 0.74146\n",
      "Seen so far: 1152 train samples, learning rate: 0.1000\n",
      "Training loss at step 9: 0.99999, dev_loss : 1.00000, nDCG@20 : 0.74146\n",
      "Seen so far: 1280 train samples, learning rate: 0.1000\n",
      "Training loss at step 10: 0.99994, dev_loss : 1.00000, nDCG@20 : 0.74127\n",
      "Seen so far: 1408 train samples, learning rate: 0.1000\n",
      "Training loss at step 11: 0.99976, dev_loss : 1.00000, nDCG@20 : 0.74184\n",
      "Seen so far: 1536 train samples, learning rate: 0.1000\n",
      "Training loss at step 12: 0.99981, dev_loss : 1.00000, nDCG@20 : 0.74182\n",
      "Seen so far: 1664 train samples, learning rate: 0.1000\n",
      "Training loss at step 13: 0.99986, dev_loss : 1.00000, nDCG@20 : 0.74185\n",
      "Seen so far: 1792 train samples, learning rate: 0.1000\n",
      "Training loss at step 14: 1.00001, dev_loss : 1.00000, nDCG@20 : 0.74196\n",
      "Seen so far: 1920 train samples, learning rate: 0.1000\n",
      "Training loss at step 15: 0.99999, dev_loss : 1.00000, nDCG@20 : 0.74131\n",
      "Seen so far: 2048 train samples, learning rate: 0.1000\n",
      "Training loss at step 16: 0.99980, dev_loss : 1.00000, nDCG@20 : 0.74131\n",
      "Seen so far: 2176 train samples, learning rate: 0.1000\n",
      "Training loss at step 17: 0.99995, dev_loss : 1.00000, nDCG@20 : 0.74134\n",
      "Seen so far: 2304 train samples, learning rate: 0.1000\n",
      "Training loss at step 18: 0.99982, dev_loss : 1.00000, nDCG@20 : 0.74150\n",
      "Seen so far: 2432 train samples, learning rate: 0.1000\n",
      "Training loss at step 19: 0.99977, dev_loss : 1.00000, nDCG@20 : 0.74149\n",
      "Seen so far: 2560 train samples, learning rate: 0.1000\n",
      "Training loss at step 20: 0.99978, dev_loss : 1.00000, nDCG@20 : 0.74158\n",
      "Seen so far: 2688 train samples, learning rate: 0.1000\n",
      "Training loss at step 21: 0.99993, dev_loss : 1.00000, nDCG@20 : 0.74151\n",
      "Seen so far: 2816 train samples, learning rate: 0.1000\n",
      "Training loss at step 22: 0.99981, dev_loss : 1.00000, nDCG@20 : 0.74159\n",
      "Seen so far: 2944 train samples, learning rate: 0.1000\n",
      "Training loss at step 23: 0.99992, dev_loss : 1.00000, nDCG@20 : 0.74159\n",
      "Seen so far: 3072 train samples, learning rate: 0.1000\n",
      "Training loss at step 24: 0.99967, dev_loss : 1.00000, nDCG@20 : 0.74159\n",
      "Seen so far: 3200 train samples, learning rate: 0.1000\n",
      "Training loss at step 25: 0.99987, dev_loss : 1.00000, nDCG@20 : 0.74162\n",
      "Seen so far: 3328 train samples, learning rate: 0.1000\n",
      "Training loss at step 26: 0.99970, dev_loss : 1.00000, nDCG@20 : 0.74162\n",
      "Seen so far: 3456 train samples, learning rate: 0.1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mndim\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   3069\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3071\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'ndim'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-fbeb2a8134ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mndcg_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'query_preprocessed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             metadata_ndcg = {'query_idf': tf.ragged.constant(ndcg_test['query_idf'], dtype=tf.float32, ragged_rank=1),\n\u001b[1;32m---> 32\u001b[1;33m                              'hist': tf.ragged.constant(ndcg_test['hist'], dtype=tf.float32, ragged_rank=1)}\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mndcg_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rel'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata_ndcg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(pylist, dtype, ragged_rank, inner_shape, name, row_splits_dtype)\u001b[0m\n\u001b[0;32m     85\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RaggedConstant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     return _constant_value(ragged_factory, constant_op.constant, pylist, dtype,\n\u001b[1;32m---> 87\u001b[1;33m                            ragged_rank, inner_shape)\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py\u001b[0m in \u001b[0;36m_constant_value\u001b[1;34m(ragged_factory, inner_factory, pylist, dtype, ragged_rank, inner_shape)\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[0minner_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m       \u001b[0minner_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default_inner_shape_for_pylist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpylist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mragged_rank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m   \u001b[1;31m# Compute default value for ragged_rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py\u001b[0m in \u001b[0;36m_default_inner_shape_for_pylist\u001b[1;34m(pylist, ragged_rank)\u001b[0m\n\u001b[0;32m    310\u001b[0m   \u001b[1;31m# use check_inner_shape to verify that other elements have the same shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m   \u001b[0minner_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_inner_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m   \u001b[0mcheck_inner_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0minner_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py\u001b[0m in \u001b[0;36mcheck_inner_shape\u001b[1;34m(item, shape)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inner values have inconsistent shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mcheck_inner_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;31m# Collapse the ragged layers to get the list of inner values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py\u001b[0m in \u001b[0;36mcheck_inner_shape\u001b[1;34m(item, shape)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inner values have inconsistent shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mcheck_inner_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;31m# Collapse the ragged layers to get the list of inner values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py\u001b[0m in \u001b[0;36mcheck_inner_shape\u001b[1;34m(item, shape)\u001b[0m\n\u001b[0;32m    288\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcheck_inner_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;34m\"\"\"Checks that `item` has a consistent shape matching `shape`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[0mis_nested\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_nested\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inner values have inconsistent shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mndim\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mndim\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   3070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3071\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3072\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_sum = 0\n",
    "ndcg_sum = 0\n",
    "step_history = []\n",
    "loss_history = []\n",
    "loss_history_dev = []\n",
    "ndcg_history = []\n",
    "\n",
    "start = time.time()\n",
    "for step, batch_train in enumerate(ds):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(batch_train)\n",
    "        loss_value = Pairwise_ranking_loss(y_true=None, y_pred=logits)\n",
    "        loss_sum += loss_value \n",
    "        \n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    if step % print_step == 0:\n",
    "        current_loss_average = float(loss_sum)/print_step\n",
    "        if step ==0:\n",
    "            current_loss_average = loss_sum\n",
    "        current_ndcg_average = float(ndcg_sum)/print_step\n",
    "        \n",
    "        logits_dev = model(metadata_dev)\n",
    "        current_loss_average_dev = Pairwise_ranking_loss(y_true=None, y_pred=logits_dev)\n",
    "        loss_sum = 0\n",
    "        \n",
    "        for q in dev_q:\n",
    "            ndcg_test = test[test['query_preprocessed'] == q]\n",
    "            metadata_ndcg = {'query_idf': tf.ragged.constant(ndcg_test['query_idf'], dtype=tf.float32, ragged_rank=1),\n",
    "                             'hist': tf.ragged.constant(ndcg_test['hist'], dtype=tf.float32, ragged_rank=1)}\n",
    "                \n",
    "            ndcg_test['rel'] = model.predict(metadata_ndcg).numpy()\n",
    "            rel_pred = list(ndcg_test.sort_values(by=['rel'], axis=0, ascending=False)['median_relevance']-1)\n",
    "            ndcg_sum += ndcg(rel_pred, p=n, form=\"exp\")\n",
    "            \n",
    "        current_ndcg_average = ndcg_sum/len(dev_q)\n",
    "        step_history.append(step)\n",
    "        loss_history.append(current_loss_average)\n",
    "        loss_history_dev.append(current_loss_average_dev)\n",
    "        ndcg_history.append(current_ndcg_average)\n",
    "        \n",
    "        print(\"Training loss at step %d: %.5f, dev_loss : %.5f, nDCG@20 : %.5f\"% (step, \n",
    "                                                                  current_loss_average, \n",
    "                                                                  current_loss_average_dev,\n",
    "                                                                  current_ndcg_average))\n",
    "        \n",
    "        print(\"Seen so far: %s train samples, learning rate: %.4f\" % ((step + 1) * batchs, learning_rate))\n",
    "        ndcg_sum = 0\n",
    "        start = time.time()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 392,
   "position": {
    "height": "414px",
    "left": "766px",
    "right": "20px",
    "top": "27px",
    "width": "518px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
