{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T10:22:37.272321Z",
     "start_time": "2020-08-01T10:22:30.116422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwon\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bert\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from ast import literal_eval\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T08:42:31.378846Z",
     "start_time": "2020-08-01T08:42:31.137986Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv').fillna('')\n",
    "train = train[['query', 'product_title', 'median_relevance']]\n",
    "max_seq_len = 87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'uncased_L-4_H-256_A-4'\n",
    "model_dir = '.models\\\\uncased_L-4_H-256_A-4\\\\' + model_name\n",
    "model_ckpt = os.path.join(model_dir, \"bert_model.ckpt\")\n",
    "model_config = os.path.join(model_dir, \"bert_config.json\")\n",
    "\n",
    "bert.bert_tokenization.validate_case_matches_checkpoint(do_lower_case=True, init_checkpoint=model_ckpt)\n",
    "vocab_file = os.path.join(model_dir, \"vocab.txt\")\n",
    "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af7f67f31654f3397b9aa0769c4152d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81835380abd6401eabfe1ed95256b150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ca55503f604c138ea173d6c21871c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3693f6948c06498b8bfd5d91fe32587b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['query_token'] = train.progress_apply(lambda x: tokenizer.tokenize(x['query']), axis=1)\n",
    "train['product_title_token'] = train.progress_apply(lambda x: tokenizer.tokenize(x['product_title']), axis=1)\n",
    "train['token'] = train.progress_apply(lambda x: [\"[CLS]\"] + x['query_token'] + [\"[SEP]\"] + x['product_title_token'] + [\"[SEP]\"], axis=1)\n",
    "train['token_ids'] = train.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x['token']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate query idf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sentences = list(train.apply(lambda x: '[CLS] ' + ' '.join(tokenizer.tokenize(\"%s %s\"%(x['query'], x['product_title']))),  axis=1))\n",
    "\n",
    "tfv = text.TfidfVectorizer(min_df=7, max_features=None, strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                           ngram_range=(1,1), use_idf=True, smooth_idf=True, sublinear_tf=True).fit(tf_sentences)\n",
    "\n",
    "feature_names = tfv.get_feature_names()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ifidf_for_words(text):\n",
    "    text_order = [tfv.transform([sen]).todense()[0,:].nonzero()[1][0] for sen in text.split(' ')]\n",
    "    tfidf_matrix= tfv.transform([text]).todense()\n",
    "    return [tfidf_matrix[0, order] for order in text_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8e658670f247dbae1685f3a12244a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cce4fb3bd704cfbaf9d0c2fe824902b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_idf_dict = {}\n",
    "for query_sentences in tqdm(train['query'].unique()):\n",
    "    query_idf_dict[query_sentences] = get_ifidf_for_words('[CLS] '+' '.join(tokenizer.tokenize(query_sentences)))\n",
    "    \n",
    "train['query_idf'] = train.progress_apply(lambda x: query_idf_dict[x['query']], axis=1)\n",
    "del query_idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate query idf softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 13\n"
     ]
    }
   ],
   "source": [
    "lq = train.query_token.map(len).max()+1\n",
    "firstk = int(train.product_title_token.map(len).mean())\n",
    "print(lq, firstk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_softmax(x, lq=8):\n",
    "    output = np.zeros(lq)\n",
    "    output[:len(x)] = x\n",
    "    output = np.exp(output) / np.sum(np.exp(output), axis=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfd8bb1f17a46868eb9af3fdbf18d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['idf_softmax'] = train.progress_apply(lambda x: idf_softmax(x['query_idf']).tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "bert_layer = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
    "token_type_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"token_type_ids\")\n",
    "\n",
    "output = bert_layer([input_ids, token_type_ids])\n",
    "\n",
    "cls_out = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :], name='CLSTokenSliceLayer')(output)\n",
    "logits = tf.keras.layers.Dense(units=4, activation='softmax')(cls_out)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_ids, token_type_ids], outputs=logits)\n",
    "model.build(input_shape=[(None, max_seq_len), (None, max_seq_len)])\n",
    "model.load_weights(\"./model_weights/class_weight_cross_entropy_Mini6.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.keras.backend.learning_phase():\n",
    "    print('change learning_phase')\n",
    "\n",
    "inp = model.input\n",
    "layers_output = {}\n",
    "for i in range(4):\n",
    "    layers_output[i] = tf.keras.models.Model([model.input], [model._layers[2]._layers[1]._layers[0][i].output])\n",
    "#     layers_output[i] = K.function([model.input], [model._layers[2]._layers[1]._layers[0][i].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(A, B):\n",
    "       return np.dot(A, B)/(np.linalg.norm(A)*np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad(x, max_seq_len=87):\n",
    "    pad_x = x + [0] * (max_seq_len - len(x))\n",
    "    return np.array(pad_x).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_layer_sim(x, layer):\n",
    "    sep_idx = x.index(102)\n",
    "    end_idx = len(x)-1\n",
    "    token_ids = [0]*(sep_idx+1) + [1]*(end_idx - sep_idx)\n",
    "    embed = layer.predict([_pad(x), _pad(token_ids)])[0]\n",
    "    sim_matrix = np.zeros(shape=(lq, firstk))\n",
    "    for i in range(lq):\n",
    "        if i < sep_idx:\n",
    "            for j in range(sep_idx+1, sep_idx+np.sum(token_ids)):\n",
    "                try:\n",
    "                    sim_matrix[i][j-sep_idx-1] = cos_sim(embed[i], embed[j])\n",
    "                except:\n",
    "                    pass\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PACRR sim matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d418ac439c438baff533b6355d16ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['sim_matrix'] = train.progress_apply(lambda x: np.stack([each_layer_sim(x['token_ids'], layers_output[i]) for i in range(4)]).tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRMM sim hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_indexing_nonzero(arr):\n",
    "    return arr[np.nonzero(arr)]\n",
    "\n",
    "def _hist(arr, bins=30):\n",
    "    hist = np.ones((bins))\n",
    "    for s in integer_indexing_nonzero(arr):\n",
    "        idx = 0\n",
    "        for i in range(bins):\n",
    "            if s >= (1/(bins))*i:\n",
    "                idx += 1\n",
    "        if idx==0:\n",
    "            hist[idx] += 1\n",
    "        else:\n",
    "            hist[idx-1] += 1\n",
    "    return np.log(hist).tolist()\n",
    "\n",
    "def DRMM_hist(x):\n",
    "    hist = []\n",
    "    for i in range(len(x['query_token'])+1):\n",
    "        hist.append(_hist(np.array(x['sim_matrix'])[:, i, :]))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b988755cb897492d89dc117b1567984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10158.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['drmm_hist'] = train.progress_apply(lambda x: DRMM_hist(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_pairwise_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairwise_dataset(df):\n",
    "    columns = ['query', \n",
    "               'product_title_P',\n",
    "               'product_title_N',\n",
    "               'median_relevance_P',\n",
    "               'median_relevance_N',\n",
    "               'drmm_hist_P', \n",
    "               'drmm_hist_N', \n",
    "               'sim_matrix_P',\n",
    "               'sim_matrix_N',\n",
    "               'query_idf_P',\n",
    "               'idf_softmax_P']\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=columns)\n",
    "    for query in tqdm(df['query'].unique()):\n",
    "        # 만족도 (4 - 3, 2, 1), (3 - 2, 1), (2 - 1) 6개 쌍으로 진행\n",
    "        for positive in [4, 3, 2]:\n",
    "            try:\n",
    "                P_temp = df[df['query']==query].groupby('median_relevance').get_group(positive)\n",
    "                for negative in range(positive)[:0:-1]:\n",
    "                    try:\n",
    "                        N_temp = df[df['query']==query].groupby('median_relevance').get_group(negative)\n",
    "                        temp = pd.merge(P_temp, N_temp, how='inner', on='query',  suffixes=('_P', '_N'))[columns]\n",
    "                        new_df = pd.concat((new_df, temp))\n",
    "                    except:\n",
    "                        # 만족도가 없는구간 pass\n",
    "                        pass\n",
    "            except:\n",
    "                # 만족도가 없는구간 pass\n",
    "                pass\n",
    "    new_df.rename(columns={'query_idf_P':'query_idf', 'idf_softmax_P':'idf_softmax'}, inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74aa57f5b4dc4753b89e302a42946fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = generate_pairwise_dataset(train)\n",
    "new_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataFrmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./data/paccr_drmm_bert_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/paccr_drmm_bert_test_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('./data/paccr_drmm_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# test_df.to_csv('./data/paccr_drmm_bert_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 312,
   "position": {
    "height": "40px",
    "left": "736px",
    "right": "20px",
    "top": "2px",
    "width": "597px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
